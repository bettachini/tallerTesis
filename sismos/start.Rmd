---
title: "Taller de tesis - Sismos"
author: "Víctor A. Bettachini"
date: "junio de 2024"
output:
  html_document
---

# R restart
```{r restart R}
# System("R")
```

# Capítulo 1: Introducción

## Contexto y motivación científica
Ver manuscrito.

## Objetivo del trabajo / pregunta
Ver manuscrito.


Encontrar los parámetros que más pesan en la percepción de un sismo en Argentina.

Para eso pienso primero probar un modelo de regresión lineal con la variable `Percibido` como dependiente y las demás como independientes.

Algo que me encantaría es factorizar la distancia entre el observador y la coordenada del sismo.
Solo tengo la columna `Provincia`, ¿será la del observador o la del sismo?



## Estructura del documento
Ver manuscrito.



# Capítulo 2: Marco teórico


# Capítulo 3: Metodología

## Presentación y descripción de los datos utilizados
Ver manuscrito.

Elaborados a partir de lo publicado por el [Instituto Nacional de Prevención Sísmica (INPRES)](http://www.inpres.gob.ar/)  
Sistematizados por Daniela Parada del Instituto de cálculo, FCEyN, UBA. [Presentamos un ejemplo para visualización de datos de sismos de Argentina de los últimos 10 años.](https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html) 




## Adquisición y formateo de los datos}


### Carga de los datos

Determino directorios de trabajo según entorno de ejecución.
```{r Directorio de trabajo: ¿Local o GitHub Codespaces?}
if (
  dir.exists(
    file.path(
      "/workspaces"
    )
  )
) {
  setwd("/workspaces/EEA-2023/trabajos_practicos/tp1")
} else {
  setwd(
    "/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/tallerTesis/sismos"
  )
}
```

```{r carga datosIC}
# No funcionó el obtener los datos tras cargar la biblioteca datosIC

# require(devtools)
# devtools::install_github("daniellaparada/datosIC")
# library(datosIC)
# datos <- sismos
# data(sismos)
```



Tras descargar al directorio local el archivo `sismos-arg.csv` desde el url `https://github.com/daniellaparada/IC-datasets-docencia/blob/main/fuente/04_visualizacion/sismos-arg.csv` lo cargo en la data.table `sismos_arg`.

```{r carga data.table , warning=F, message=F}
if (!require("data.table")) {
  install.packages("data.table")
}
library("data.table")

## DT[i, j, by]
##   R:                 i                 j        by
## SQL:  where | order by   select | update  group by
```

Genero la data.table a partir del archivo ubicado en el sendero (path) del sistema de archivos local.
```{r Lectura del archivo}
sismos_all <- fread("./sismos_all.csv", sep = ",") # este no tiene la columna de si fue percibido
sismos_arg <- fread("./sismos-arg.csv", sep = ",")
```

Se verifica que se cargó
```{r head de la data.table}
head(sismos_all)
```

```{r nombres columnas iguales a publicado}
colnames(sismos_arg)
```
Aquí si figura el booleano de si fue percibido



### Verificación de faltantes o duplicados

```{r datos faltantes}
sum(is.na(sismos_arg))
```
No hay registros con "no números" ("not a number" o NA).

```{r datos con cero}
# check at each column for any instance of 0
sapply(sismos_arg, function(x) sum(x == 0))
```
No hay registros idénticos a '0' en ninguna columna.

```{r datos duplicados número}
nrow(sismos_arg)
duplicados <- sismos_arg[duplicated(sismos_arg, fromLast = TRUE)]
#length duplicados
c(nrow(duplicados), nrow(sismos_arg), nrow(duplicados)/nrow(sismos_arg) )
```
Esos 23 registros son un 0.04% de los 55817 registros.

```{r datos duplicados todas las ocurrencias}
# find out whether two rows are equal
all_duplicates <- sismos_arg[duplicated(sismos_arg) | duplicated(sismos_arg, fromLast = TRUE)]
all_duplicates
```

```{r sin duplicados}
sismos <- sismos_arg[!duplicated(sismos_arg)]
```
En `sismos` queda un data.table sin duplicados.



### Inspección y formateo de datos
```{r tipo de dato}
str(sismos)
```


#### Escala continua para fecha y hora del sismo
```{r Segundos del día}
# Function to convert hh:mm:ss to seconds past midnight
convert_to_seconds <- function(time_str) {
  time_posix <- strptime(time_str, format="%H:%M:%S")
  seconds <- as.numeric(format(time_posix, "%H")) * 3600 +
             as.numeric(format(time_posix, "%M")) * 60 +
             as.numeric(format(time_posix, "%S"))
  return(seconds)
}

# Apply the function to the time_str column
sismos[, `Segundos del día` := sapply(Hora, convert_to_seconds)]

summary(sismos[ ,`Segundos del día`, ])
```

```{r día del año}
# consecutive day at the year

# if (!require("lubridate")) {
#   install.packages("lubridate")
# }
# library("lubridate")

# sismos[, `Día del año` := lubridate::yday(as.Date(Fecha, format = "%Y-%m-%d")), ]

sismos[, `Día del año` := yday(as.Date(Fecha, format = "%Y-%m-%d")), ]
summary(sismos[, "Día del año", ], )
```


```{r año}
sismos[, Año := year(as.Date(Fecha, format = "%Y-%m-%d"))]
summary(sismos[,Año])
```



### Delimitación del espacio geográfico

#### Distribución geográfica de los datos
Hay código en (https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html#exploraci%C3%B3n-inicial) pero se tomaron las imágenes de allí.



### El problema de la distancia

### Elección de la provincia de San Juan
```{r select rows of San Juan}
sismos_SJ <- sismos[Provincia == "San Juan", ]
# delete column Provincia
sismos_SJ <- sismos_SJ[, Provincia := NULL]
```

```{r registros SJ}
c(nrow(sismos), nrow(sismos_SJ), nrow(sismos_SJ)/nrow(sismos))
```




# Análisis exploratorio de datos
Una básica estadística descriptiva de los datos
```{r resumen de la data.table}
summary(sismos_SJ)
```
Hay un fuerte desbalance en la variable `percibido` que indica si el sismo fue percibido o no hacia este último caso.
  
```{r fracción de no percibidos}
n_percibidos <- sum(sismos_SJ$Percibido == "TRUE")
c(n_percibidos,  n_percibidos / nrow(sismos_SJ) )
```




## Magnitud: distribución lineal y escala de Richter
```{r dplyr}
if (!require("dplyr")) {
  install.packages("dplyr")
}
library("dplyr")
```

```{r Magnitud San Juan}
sismos_SJaux <- sismos_SJ %>%
  mutate(Año = format(Fecha, format = "%Y"))

df <- sismos_SJaux %>%
  filter(Año > 2011,
         Año < 2023) %>%
  group_by(Año, Magnitud) %>%
  summarize(n = n())


df2 <- df %>%
  group_by(Año) %>%
  arrange(-Magnitud) %>%
  summarize(Magnitud = Magnitud,
            nacum = cumsum(n))
```

```{r plotly}
if (!require("plotly")) {
  install.packages("plotly")
}
library("plotly")
```

```{r plot acumulado anuales por magnitud San Juan}
#ggplotly(
#  ggplot(data = df2, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año, key = nacum
#  )) +
#    labs(x = "Magnitud", y = "(Log 10) Cantidad acumulada de sismos") +
#    geom_point() +
#    theme_classic(),
#  source = "select",
#  tooltip = c("key")
#)
```

```{r TikZ}
library(tikzDevice)
if (!require("tikzDevice")) {
  install.packages("tikzDevice")
}
library("tikzDevice")
```

```{r output acumulado anuales por magnitud San Juan tikz}
#tikz('graphs/acumulado_anual_magnitud.tex',width=5,height=3)
#  ggplot(data = df2, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año)) +
#    labs(x = "Magnitud ($M_w$)", y = "Número sismos (Log$_{10}$)") +
#    geom_point() +
#    theme_classic()
#dev.off()
```


```{r Magnitud San Juan percibidos}
df_detectados <- sismos_SJaux %>%
  filter(Año > 2011,
         Año < 2023,
         Percibido == TRUE) %>%
  group_by(Año, Magnitud) %>%
  summarize(n = n())

df2_detectados <- df_detectados %>%
  group_by(Año) %>%
  arrange(-Magnitud) %>%
  summarize(Magnitud = Magnitud,
            nacum = cumsum(n))

#ggplotly(
#  ggplot(data = df2_detectados, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año, key = nacum
#  )) +
#    labs(x = "Magnitud", y = "(Log 10) Cantidad acumulada de sismos") +
#    geom_point() +
#    theme_classic(),
#  source = "select",
#  tooltip = c("key")
#)
```

```{r output acumulado anuales por magnitud San Juan percibidos tikz}
#tikz('graphs/acumulado_anual_magnitud_percibidos.tex',width=5,height=3)
#  ggplot(data = df2_detectados, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año)) +
#    labs(x = "Magnitud ($M_w$)", y = "Número sismos (Log$_{10}$)") +
#    geom_point() +
#    theme_classic()
#dev.off()
```
 



### Horario de los percibidos
```{r percibidos segmentados por hora}
# Create two separate data.tables for TRUE and FALSE cases
dt_true <- sismos_SJ[Percibido == TRUE]
dt_false <- sismos_SJ[Percibido == FALSE]

# Define the breaks for the 24 hours of the day (0 to 86400 seconds)
breaks <- seq(0, 86400, by = 3600)

# Create histograms for TRUE and FALSE cases
hist_true <- hist(dt_true$`Segundos del día`, breaks = breaks, plot = FALSE)
hist_false <- hist(dt_false$`Segundos del día`, breaks = breaks, plot = FALSE)

# Calculate the ratio of counts in each bin
ratio <- hist_true$counts / hist_false$counts

# Create a data.table to hold the result
percibidos_hora <- data.table(
  Hora = floor(hist_true$mids / 3600), # Convert bin midpoints to hours
  Porcentaje = ratio * 100
)

# Handle possible Inf or NA values in the ratio
percibidos_hora[is.infinite(Porcentaje) | is.na(Porcentaje), Porcentaje := NA]

# Print the result
print(percibidos_hora)
```


```{r histograma percibidos segmentados por hora}
#ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
#  geom_bar(stat = "identity") +
#  # labs(title = "Razón de sismos percibidos a no percibidos por hora",
#  labs(
#       x = "Hora",
#       y = "Percibidos [%]")
## percibido_hora_histograma <- recordPlot() # no funca
#
#tikz('graphs/histograma_percibidos_por_hora.tex',width= 4.8,height=2)
## replayPlot(percibido_hora_histograma) @ no funca
#ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
#  geom_bar(stat = "identity") +
#  labs(x = "Hora", y = "Percibidos [\\%]"
#  )
#dev.off()
```


#### Distribución de los sismos percibidos por trimestre
```{r percibidos por trimestre}
trimestre_días = ceiling(366/4)
#
## Define the breaks for the 24 hours of the day (0 to 86400 seconds)
breaks_trimestre <- seq(0, 400, by = trimestre_días)
#
## Create histograms for TRUE and FALSE cases
hist_true_trimestre <- hist(dt_true$`Día del año`, breaks = breaks_trimestre, plot = FALSE)
hist_false_trimestre <- hist(dt_false$`Día del año`, breaks = breaks_trimestre, plot = FALSE)
#
## Calculate the ratio of counts in each bin
ratio_trimestre <- hist_true_trimestre$counts / hist_false_trimestre$counts
#
## Create a data.table to hold the result
percibidos_trimestre <- data.table(
  Trimestre = ceiling(hist_true_trimestre$mids / trimestre_días), # Convert bin midpoints to hours
  Porcentaje_trimestre = ratio_trimestre * 100
)
#
## Handle possible Inf or NA values in the ratio
percibidos_trimestre[is.infinite(Porcentaje_trimestre) | is.na(Porcentaje_trimestre), Porcentaje_trimestre := NA]
#
## Print the result
print(percibidos_trimestre)
```


```{r histograma percibidos segmentados por trimestre}
#ggplot(percibidos_trimestre, aes(x = Trimestre, y = Porcentaje_trimestre)) +
#  geom_bar(stat = "identity") +
##  # labs(title = "Razón de sismos percibidos por trimestre",
#  labs(
#       x = "Trimestre",
#       y = "Percibidos [%]")
### percibidos_trimestre_histograma <- recordPlot() # No funca
#
#tikz('graphs/percibidos_trimestre_histograma.tex',width= 4.8,height=2)
### replayPlot(percibidos_trimestre_histograma) # No funca
#ggplot(percibidos_trimestre, aes(x = Trimestre, y = Porcentaje_trimestre)) +
#  geom_bar(stat = "identity") +
#  labs(x = "", y = "Percibidos [\\%]"
#  )
#dev.off()
```

```{r trimestre}
# data type percibidos_trimestre
str(percibidos_trimestre)

# z-scores
data <- percibidos_trimestre[, Porcentaje_trimestre]
z_scores <- (data - mean(data))/sd(data)
z_scores

# p-values
p_values <- 2 * (1 - pnorm(abs(z_scores)))
p_values
```

```{r trimestre test de Dixon}
if (!require("outliers")) {
  install.packages("outliers")
}
library("outliers")

# Dixon's Q test
outliers::dixon.test(data, opposite = FALSE)
```


```{r data.table with hist_false hist_true}
hist_true_trimestre$counts
hist_false_trimestre$counts
trials = hist_true_trimestre$counts +hist_false_trimestre$counts
prop.test(hist_true_trimestre$counts, trials)
```


```{r trimestre test exacta binomial}
# Group data (successes and trials)
groups <- list('1' = c(215, 8261), '2' = c(152, 7553), '3' = c(112, 6857), '4' = c(138, 7246))
mean_proportion <- mean(sapply(groups, function(group) group[1] / group[2]))

# Perform binomial tests for each group
results <- lapply(names(groups), function(group) {
  successes <- groups[[group]][1]
  trials <- groups[[group]][2]
  test <- binom.test(successes, trials, p = mean_proportion)
  return(list(group = group, p_value = test$p.value, proportion = successes / trials))
})

# Print results
for (result in results) {
  cat(sprintf("Group %s: Proportion = %f, p-value = %f\n", result$group, result$proportion, result$p_value))
}
```

### Ingeniería de características


### Descarte de terromotos de poca profundidad
```{r máxima profundidad}
c(min(sismos_SJ$Profundidad),  max(sismos_SJ$Profundidad) )
```

```{r histograma hasta 50 km profundidad con barras más finas}
#hist(sismos_SJ[Profundidad < 50]$Profundidad, main = "", xlab = "Profundidad [km]", ylab = "Frecuencia", breaks = 50)
#profundidad_menos50 <- recordPlot()
#
##png("graphs/histograma_profundidad_menos50.png", width = 400, height = 400, res = 100)
##replayPlot(profundidad_menos50)
##dev.off()
#
## save as TikZ 
#tikz('graphs/histograma_profundidad_menos50.tex',width=5,height=4) # petite
#replayPlot(profundidad_menos50)
#dev.off()
```

```{r solo registros con profundidad no nula}
# copy of data.table
# sismos_todasProfundidades <- copy(sismos)
sismos_SJ <- sismos_SJ[Profundidad > 0]
```

```{r histograma de Profundidad}
#hist(sismos_SJ$Profundidad, main = "", xlab = "Profundidad [km]", ylab = "Frecuencia", breaks = 50)
#histograma_profundidad750km <- recordPlot()
#
### save as TikZ 
#tikz('graphs/histograma_profundidad750km.tex',width=5,height=4) # petite
#replayPlot(histograma_profundidad750km)
#dev.off()
```



#### Linealización de la Magnitud
Puesto que la escala de Richter es una escala logarítmica me interesaría pasarla a una escala lineal.

> The Richter magnitude of an earthquake is determined from the logarithm of the amplitude of waves recorded by seismographs. Adjustments are included to compensate for the variation in the distance between the various seismographs and the epicenter of the earthquake. The original formula is:
> $$
> M_\mathrm{L} = \log_{10} A - \log_{10} A_\mathrm{0}(\delta) = \log_{10} [A / A_\mathrm{0}(\delta)]
> $$
> 
> Fuente: https://en.wikipedia.org/wiki/Richter_scale

La presunción es que el umbral de percepción estará ligado a la amplitud de oscilación de las ondas sísmicas.  
Aunque también podría pensarse que sería con su potencia, es decir algo proporcional a $A^2$.  
Algo para probar luego, por lo pronto a pasarle a una escala lineal.

```{r proporción más profundos que 50 km}
# only those with Profundidad > 50
c( nrow(sismos_SJ[Profundidad > 50]), nrow(sismos_SJ[Profundidad < 50]) )
nrow(sismos_SJ[Profundidad > 50])/  nrow(sismos_SJ)
```


Sin ponerme a investigar más genero una columna de magnitud_lineal con $10^{M_L}$
```{r min Magnitud}
magnitud_mínima = min(sismos_SJ[,Magnitud, ])
magnitud_mínima
```

```{r Linealizar la escala de Richter}
sismos_SJ[, "Proxy_amplitud" := 10^(Magnitud- magnitud_mínima)]
```

```{r descripción para magnitud lineal}
# summary(sismos_SJ$"Proxy_amplitud")
summary(sismos_SJ[,'Proxy_amplitud'])
```


### Percecpión sísmica, ¿de amplitud o energía?
```{r proxy energía}
sismos_SJ[, `Proxy_energía` := `Proxy_amplitud`^2]
```



## Variables a correlacionar con la percepción 
```{r variables posibles}
colnames(sismos_SJ)
```


Podría verse si hay puede hacerse un heat map de correlaciones entre estas variables con 'Percibido'.

```{r correlación variables}
# use any tool
corr_alles <- cor(
  sismos_SJ[
    ,
    .(`Latitud`, `Longitud`, `Magnitud`, `Profundidad`, `Proxy_amplitud`, `Proxy_energía`, Percibido)
    ]
    , use = "complete.obs"
    )
# corr_alles <- cor(sismos_SJ[, .(Hora_decimal, Profundidad, Proxy_amplitud, Percibido)], use = "complete.obs")
# percibido_correlación = str(corr_alles)

# only the last column
percibido_correlación = corr_alles[, 7]

# remove Percibido from percibido_correlación
percibido_correlación <- percibido_correlación[-7]

# sort
percibido_correlación <- percibido_correlación[order(percibido_correlación, decreasing = TRUE)]
percibido_correlación
```

```{r correlación magnitud y longitud}
cor(sismos_SJ[, .(`Longitud`,`Magnitud`)], use = "complete.obs")
```



```{r correlación magnitud y derivados}
cor(sismos_SJ[, .(`Magnitud`, `Proxy_amplitud`, `Proxy_energía`)], use = "complete.obs")
```




## Preprocesamiento
Las evaluaciones sobre la calidad de los modelos de clasificación generados se realizarán sobre un subconjuntos de ensayo (test) del \(20 \%\) de los datos de la provincia de San Juan, el resto se utilizará para el entrenamiento (train).


### Escalamiento
Previo a la partición (splitting) se realiza un escaleo uniforme sobre todo el conjunto de datos (scaling) de las tres características numéricas.
Para esto se hace uso de la función `scale` de la biblioteca base de R.
El objeto de hacer esto previo a un ajuste lineal es que los coeficientes de la regresión sean comparables entre sí.

```{r escalamiento}
# identify numerical features in the data
numerical_features <- c("Latitud", "Longitud", "Magnitud", "Profundidad", "Proxy_amplitud", "Proxy_energía")

# copier tout
sismos_SJ_escalado <- copy(sismos_SJ)

# copy numerical_features and Percibido to sismos_SJ_escalado
sismos_SJ_escalado <- sismos_SJ[, c("Percibido", ..numerical_features)]

# copy only numerical features and Percibido
# sismos_SJ_escalado <- sismos_SJ[, ..numerical_features, Percibido]
# # copy only numerical features
# sismos_SJ_escalado <- sismos_SJ[, ..numerical_features]

# Scale numerical features
sismos_SJ_escalado[, (numerical_features) := lapply(.SD, scale), .SDcols = numerical_features]

head(sismos_SJ_escalado)
```

```{r}
# correlation between columns Magnitud and Proxy_amplitud
cor(sismos_SJ[, `Proxy_amplitud`], sismos_SJ[, Magnitud])
cor(sismos_SJ_escalado[, `Proxy_amplitud`], sismos_SJ_escalado[, Magnitud])
```
Bien, la correlación no cambia. Eso indica que funciona bien el escalado.



### División con estratificación
Dado el desbalance de la clase Percibido comentado en la sección xxx, la división de los datos en subconjuntos entrenamiento y prueba se hará con estratificación usando la función \verb'CreateDataPartion'.
```{r biblioteca caret}
if(!require("caret")) {
  install.packages("caret")
}
library("caret")
```

```{r división con estratificación}
# Split the data into training and testing sets
set.seed(123)
train_index <- caret::createDataPartition(sismos_SJ_escalado[ , Percibido], p = 0.8, list = FALSE)
entrenamiento_SJ <- sismos_SJ_escalado[train_index]
ensayo_SJ <- sismos_SJ_escalado[-train_index]

# Print the number of observations in each set
c(nrow(entrenamiento_SJ), nrow(ensayo_SJ))
```

```{r}
# correlation between columns Magnitud and Proxy_amplitud
cor(entrenamiento_SJ[, `Proxy_amplitud`], entrenamiento_SJ[, Magnitud])
```


### Corrección del desbalance
```{r corrección del desbalance}
if (!require("ROSE")) {
  install.packages("ROSE")
}
library("ROSE")

# Percibido como factor para el imbalance
entrenamiento_SJ[, Percibido := as.factor(Percibido)]

# Apply the ROSE algorithm to correct the imbalance
# entrenamiento_SJ_balanceado <- ovun.sample(Percibido ~ ., data = entrenamiento_SJ, method = "over", N = nrow(entrenamiento_SJ), seed = 123)$data

# Define the numerical features with backticks
numerical_features <- c("Latitud", "Longitud", "Magnitud", "Profundidad", "`Proxy_amplitud`", "`Proxy_energía`")

# Create the formula as a string and convert it to a formula object
formula_str <- paste("Percibido ~", paste(numerical_features, collapse = " + "))
formula <- as.formula(formula_str)

# Apply the ROSE function with the dynamically created formula
entrenamiento_SJ_balanceado <- ROSE(formula, data = entrenamiento_SJ, seed = 123)$data
#entrenamiento_SJ_balanceado <- ROSE(Percibido ~ ., data = entrenamiento_SJ, seed = 123)$data

# data.table
entrenamiento_SJ_balanceado <- as.data.table(entrenamiento_SJ_balanceado)

# Print the number of observations in each set
c(nrow(entrenamiento_SJ_balanceado), nrow(ensayo_SJ))
```

```{r verificación del balanceo}
# Check the balance of the target variable in training set
table(entrenamiento_SJ_balanceado$Percibido)

# Check the balance of the target variable in test set, must still be unbalanced
table(ensayo_SJ$Percibido)
```

```{r}
# correlation between columns Magnitud and Proxy_amplitud
cor(entrenamiento_SJ[, `Proxy_amplitud`], entrenamiento_SJ[, Magnitud])
cor(entrenamiento_SJ_balanceado[, `Proxy_amplitud`], entrenamiento_SJ_balanceado[, Magnitud])
```



## Descripción de las métricas de evaluación de los modelos (si corresponde)


## Descripción de los métodos estadísticos utilizados (si corresponde)
Contar sobre regresión logística aplicada a variables categóricas y sobre el XFGBoost.



### Regresión logística múltiple

Utilizaré como base el código de Enfoque estadístico del aprendizaje, clase 9, dedicada a logit.
```{r biblioteca ajuste regresión lineal}
# if (!require("glmnet")) {
#   install.packages("glmnet")
# }
# library("glmnet")
if (!require("glm2")) {
    install.packages("glm2")
}
library("glm2")
```


#### sin interacción entre variables

```{r múltiple definición}
# Fit a logistic regression model
logit_model <- glm2::glm2(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~ Magnitud + `Proxy_amplitud` + `Proxy_energía` + Longitud + Latitud + Profundidad,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```

```{r múltiple significativos}
# Print the summary of the model
summary(logit_model)
```
Del sumario se indica con p-values que las variables derivadas de la magnitud son menos significativas que las originales, en particular `proxy_energía` tiene un p-value excediendo 0.05.

```{r tidy biblioteca}
#if (!require("broom")) {
#  install.packages("broom")
#}
#library("broom")
```

```{r tidy logit_model}
## Convert the model summary to a tidy data frame
#logit_model_tidy <- tidy(logit_model)
#logit_model_tidy
```
Francamente no aporta nada que no dé summary, y de hecho oscurece con la terminología statistic y p-value en lugar de z-value y Pr(>|z|).



#### Interacción entre variables

```{r heat map correlations}
# Create a copy of the data.frame excluding a specific column
temp <- select(entrenamiento_SJ_balanceado, -Percibido)
cor_matrix <- cor(temp)
cor_matrix
```

```{r}
# Get number of variables (assuming square matrix)
n <- ncol(cor_matrix)

# Convert correlation matrix to long format
cor_long <- as.data.table(as.table(cor_matrix))

# Extract variable names
var_names <- colnames(cor_matrix)

# Rename columns and remove self-correlation (value = 1)
cor_long <- cor_long[, .(V1 = rep(var_names, n), V2 = rep(var_names, each = n), value = as.vector(cor_matrix))]
cor_long <- cor_long[V1 != V2]

# Sort by absolute correlation values
sorted_cor_dt <- cor_long[order(abs(value), decreasing = TRUE)]

# Print the sorted correlations with variable pairs and values
print(sorted_cor_dt[, .(Variable_Pair = paste(V1, "-", V2), Absolute_Value = abs(value))])
```


```{r}
# Get lower triangle of the correlation matrix
  get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
  # Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

upper_tri <- get_upper_tri(cor_matrix)

library(reshape2)
melted_cormat <- melt(upper_tri, na.rm = TRUE)

## Heatmap
#if(!require("ggplot2")) {
#  install.packages("ggplot2")
#}
#library("ggplot2")
#
#ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
# geom_tile(color = "white")+
# scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
#   midpoint = 0, limit = c(-1,1), space = "Lab", 
#   name="Pearson\nCorrelation") +
#  theme_minimal()+ 
# theme(axis.text.x = element_text(angle = 45, vjust = 1, 
#    size = 12, hjust = 1))+
# coord_fixed()
```



```{r}
# Fit a logistic regression model
logit_pairwise <- glm2::glm2(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~
    Magnitud +
    `Proxy_amplitud` +
    `Proxy_energía` +
    Longitud +
    Latitud +
    Profundidad +
    `Proxy_energía` * `Proxy_amplitud` +
    `Proxy_amplitud` * Magnitud +
    Profundidad * Longitud +
    `Proxy_energía` * Magnitud +
    Magnitud * Longitud +
    Profundidad * Latitud
    ,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```

```{r múltiple significativos}
# Print the summary of the model
summary(logit_pairwise)
```

Nuevamente los p-values indican que las interacciones no aportan significativamente al modelo, como muestra el cuadro




#### Medida de la bondad del ajuste

Modelo original sin interacciones logit_model

Deviance
```{r deviance based pseudo R squared}
# if(!require("broom")) {
#   install.packages("broom")
# }
# library("broom")

# Calculate the pseudo R-squared
pseudo_r2_sin <- 1 - logit_model$deviance / logit_model$null.deviance
pseudo_r2_sin
```

AIC
```{r AIC}
# Calculate the AIC
aic_sin <-  AIC(logit_model)
aic_sin
```

```{r Hosmer-Lemeshow Test}
if(!require("ResourceSelection")) {
  install.packages("ResourceSelection")
}
library("ResourceSelection")

# Hosmer-Lemeshow Test
factor_forHL <- as.numeric(entrenamiento_SJ_balanceado$Percibido) - 1
hl_test_sin <- ResourceSelection::hoslem.test(factor_forHL, fitted(logit_model))
print(hl_test_sin)
```


##### Sin interacciones limpio
```{r Modelo sin interacciones limpio}
# Fit a logistic regression model
logit_model_limpio <- glm2::glm2(
  Percibido ~ Magnitud + Longitud + Latitud + Profundidad,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```

```{r sin_limpio deviance based pseudo R squared}
pseudo_r2_sin_limpio <- 1 - logit_model_limpio$deviance / logit_model_limpio$null.deviance
pseudo_r2_sin_limpio
```

```{r AIC}
# Calculate the AIC
aic_sin_limpio <-  AIC(logit_model_limpio)
aic_sin_limpio
```

```{r}
hl_test_sin_limpio <- ResourceSelection::hoslem.test(factor_forHL, fitted(logit_model_limpio))
print(hl_test_sin_limpio)
```


###### Pairwise 
```{r}
pseudo_r2_pairwise <- 1 - logit_pairwise$deviance / logit_pairwise$null.deviance
pseudo_r2_pairwise
```

```{r AIC}
# Calculate the AIC
aic_pairwise <-  AIC(logit_pairwise)
aic_pairwise
```

```{r}
hl_test_pairwise <- ResourceSelection::hoslem.test(factor_forHL, fitted(logit_pairwise))
print(hl_test_pairwise)
```


###### Pairwise limpio
```{r}
# Fit a logistic regression model
logit_pairwise_limpio <- glm2::glm2(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~
    Magnitud +
    Longitud +
    Latitud +
    Profundidad +
    Profundidad * Longitud +
    Magnitud * Longitud +
    Profundidad * Latitud
    ,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```

```{r}
pseudo_r2_pairwise_limpio <- 1 - logit_pairwise_limpio$deviance / logit_pairwise_limpio$null.deviance
pseudo_r2_pairwise_limpio
```

```{r AIC}
# Calculate the AIC
aic_pairwise_limpio <-  AIC(logit_pairwise_limpio)
aic_pairwise_limpio
```

```{r}
hl_test_pairwise_limpio <- ResourceSelection::hoslem.test(factor_forHL, fitted(logit_pairwise_limpio))
print(hl_test_pairwise_limpio)
```




###### Hostmer-Lemeshow plot (no funca)
```{r Hostmer-Lemeshow plot function}
if(!require("OneR")) {
  install.packages("OneR")
}
library("OneR")

Hosmer_Lemeshow_plot <- function(dataset, predicted_column, class_column, bins, positive_value, color='forestgreen', nudge_x=0, nudge_y=0.05){
  # Asignar los grupos a las observaciones de acuerdo a la probabilidad predicha
  dataset['group'] <- bin(dataset[predicted_column], nbins = bins, method = 'l', labels=c(1:bins))
  # Contar la cantidad de casos positivos por grupo
  positive_class <- dataset %>% filter(!!sym(class_column)==positive_value) %>% group_by(group) %>% count()
  # Obtener la media de las predicciones por grupo
  HL_df <- dataset %>% group_by(group) %>% summarise(pred=mean(!!sym(predicted_column)), count=n()) %>%
            inner_join(.,positive_class) %>%
            mutate(freq=n/count)
  # Gráfico 
  HM_plot <- ggplot(HL_df, aes(x=pred, y=freq)) + 
    geom_point(aes(size=n), color=color) +
    geom_text(aes(label=n),nudge_y = nudge_y)+
    geom_abline(slope = 1, intercept = 0, linetype='dashed') + 
    theme_bw() +
    labs(title='Hosmer-Lemeshow', size='Casos', x="Probabilidad Predicha", y="Frecuencia observada")
  return(HM_plot)
}
```


```{r múltiple predicciones}
# Make predictions on the test set
prediction_full <- predict(logit_pairwise_limpio, newdata = ensayo_SJ, type = "response")

# Print the first few predictions
head(prediction_full)
```



```{r Hostmer-Lemeshow plot}
Hosmer_Lemeshow_plot(prediction_full, '.fitted', 'Percibido', 10, 1) +
  labs(subtitle="Modelo completo")
```



#### Evaluación de la predicción del modelo logístico


```{r múltiple metrics function}
# Define the prediction metrics function
prediction_metrics <- function(cutoff, predictions, actual) {
  # Example adjustment if Percibido is boolean
  actual <- factor(actual, levels = c(FALSE, TRUE))
  predicted_class <- factor(ifelse(predictions > cutoff, TRUE, FALSE), levels = c(FALSE, TRUE))

  # Ensure there is at least one instance of each class
  if (length(unique(predicted_class)) < 2 || length(unique(actual)) < 2) {
    return(data.frame(
      cutoff = cutoff,
      accuracy = NA,
      sensitivity = NA,
      specificity = NA,
      precision = NA,
      f1 = NA
    ))
  }

  cm <- confusionMatrix(predicted_class, actual, positive = "TRUE")
  
  data.frame(
    cutoff = cutoff,
    accuracy = cm$overall['Accuracy'],
    sensitivity = cm$byClass['Sensitivity'],
    specificity = cm$byClass['Specificity'],
    precision = cm$byClass['Precision'],
    F1 = cm$byClass['F1']
  )
}
```


##### Modelo con interacciones pero sin verivadas de magnitud

```{r}
# Make predictions on the test set
prediction_full <- predict(logit_pairwise_limpio, newdata = ensayo_SJ, type = "response")

# Print the first few predictions
# head(prediction_full)
```


```{r múltiple metrics_list}
cutoffs <- seq(0.05, 0.95, by = 0.01)

# Calculate metrics for each cutoff value
metrics_list <- lapply(cutoffs, function(cutoff) {
  prediction_metrics(cutoff, predictions = prediction_full, actual = ensayo_SJ$Percibido)
})

# Print the first few elements of metrics_list to check
# head(metrics_list)
```

```{r tidyverse}
if(!require("tidyverse")) {
  install.packages("tidyverse")
}
library("tidyverse")
```

```{r múltiple metrics plot}
## Combine the list of data frames into a single data frame
#logit_pred <- do.call(rbind, metrics_list)
#
## Reshape the data for plotting
#logit_pred <- logit_pred %>%
#  pivot_longer(cols = -cutoff, names_to = "term", values_to = "estimate") %>%
#  mutate(estimate = round(estimate, 3))
#
## Plot the results
#ggplot(logit_pred, aes(cutoff, estimate, group = term, color = term)) +
#  geom_line(size = 1) +
#  theme_bw() #+
```


```{r}
# Combine the list of data frames into a single data frame
logit_pred <- do.call(rbind, metrics_list)

# Reshape the data for plotting and rename columns
logit_pred <- logit_pred %>%
  pivot_longer(cols = -cutoff, names_to = "métrica", values_to = "valor") %>%
  mutate(
    valor = round(valor, 3),
    métrica = recode(
      métrica,
      "accuracy" = "exactitud",
      "precision" = "precisión",
      "sensitivity" = "sensibilidad",
      "specificity" = "especificidad"
      )
    ) # Incluido también "specificity"

# Plot the results
#ggplot(logit_pred, aes(cutoff, valor, group = métrica, color = métrica)) +
#  geom_line(size = 1) +
#  labs(
#       x = "Corte",
#       y = "Valor",
#       color = "Métricas") +
#  theme_bw()
```

```{r}
tikz('graphs/múltiple_metrics.tex',width=5,height=2)
ggplot(logit_pred, aes(cutoff, valor, group = métrica, color = métrica)) +
  geom_line(size = 1) +
  labs(
       x = "Corte",
       y = "Valor",
       color = "Métricas") +
  theme_bw()
dev.off()
```

```{r}
# Calculate metrics for the chosen cutoff value
corte = 0.6
prediction_metrics(
  corte, 
  predictions = prediction_full, 
  actual = ensayo_SJ$Percibido
  )
```



##### Modelo con interacciones con verivadas de magnitud

```{r}
# Make predictions on the test set
prediction_full <- predict(logit_pairwise, newdata = ensayo_SJ, type = "response")

# Print the first few predictions
# head(prediction_full)
```

```{r}
cutoffs <- seq(0.05, 0.95, by = 0.01)

# Calculate metrics for each cutoff value
metrics_list <- lapply(cutoffs, function(cutoff) {
  prediction_metrics(cutoff, predictions = prediction_full, actual = ensayo_SJ$Percibido)
})

# Print the first few elements of metrics_list to check
# head(metrics_list)
```

```{r}
# Combine the list of data frames into a single data frame
logit_pred <- do.call(rbind, metrics_list)

# Reshape the data for plotting and rename columns
logit_pred <- logit_pred %>%
  pivot_longer(cols = -cutoff, names_to = "métrica", values_to = "valor") %>%
  mutate(
    valor = round(valor, 3),
    métrica = recode(
      métrica,
      "accuracy" = "exactitud",
      "precision" = "precisión",
      "sensitivity" = "sensibilidad",
      "specificity" = "especificidad"
      )
    ) # Incluido también "specificity"

## Plot the results
#ggplot(logit_pred, aes(cutoff, valor, group = métrica, color = métrica)) +
#  geom_line(size = 1) +
#  labs(
#       x = "Corte",
#       y = "Valor",
#       color = "Métricas") +
#  theme_bw()
```

```{r}
tikz('graphs/múltiple_derivadas.tex',width=5,height=2)
ggplot(logit_pred, aes(cutoff, valor, group = métrica, color = métrica)) +
  geom_line(size = 1) +
  labs(
       x = "Corte",
       y = "Valor",
       color = "Métricas") +
  theme_bw()
dev.off()
```

```{r}
# Calculate metrics for the chosen cutoff value
corte = 0.6
prediction_metrics(
  corte, 
  predictions = prediction_full, 
  actual = ensayo_SJ$Percibido
  )
```







## Predictor por XGBoost

```{r biblioteca xgboost}
if (!require("xgboost")) {
  install.packages("xgboost")
}
library("xgboost")
```

```{r first train}
# convert to data to matrix
num_feat = c("Latitud", "Longitud", "Magnitud", "Profundidad", "Proxy_amplitud", "Proxy_energía")
entrenamiento_SJ_balanceado_matrix <- as.matrix(entrenamiento_SJ_balanceado[ ,..num_feat])
label_numeric <- as.numeric(entrenamiento_SJ_balanceado[, Percibido]) - 1
bstSparse <- xgboost(
  data = entrenamiento_SJ_balanceado_matrix, 
  label = label_numeric, 
  max.depth = 5, eta = 1, 
  nthread = 2, nrounds = 5, 
  objective = "binary:logistic", 
  verbose = 2
  )
```

```{r premiere prediction}
ensayo_SJ_matrix <- as.matrix(ensayo_SJ[ ,..num_feat])
prediction_xgboost <- predict(bstSparse, ensayo_SJ_matrix)
umbral_p = 0.5
prediction_xgboost_binario <- ifelse(prediction_xgboost > umbral_p, 1, 0)
```

```{r metrics}
# confusion matrix
confusion_matrix <- table(ensayo_SJ$Percibido, prediction_xgboost_binario)

# accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

# sensitivity
sensitivity <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])

# specificity
specificity <- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])

# precision
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])

# F1
F1 <- 2 * (precision * sensitivity) / (precision + sensitivity)

# print the metrics
c(accuracy, sensitivity, specificity, precision, F1)
```
  max.depth = 5, eta = 1, 
  nthread = 2, nrounds = 5, 
[1] 0.9804413 0.1138211 0.9986346 0.6363636 0.1931034



#### Now without the derivatives
```{r}
num_feat = c("Latitud", "Longitud", "Magnitud", "Profundidad")
entrenamiento_SJ_balanceado_matrix <- as.matrix(entrenamiento_SJ_balanceado[ ,..num_feat])
label_numeric <- as.numeric(entrenamiento_SJ_balanceado[, Percibido]) - 1
bstSparse <- xgboost(
  data = entrenamiento_SJ_balanceado_matrix, 
  label = label_numeric, 
  max.depth = 3, eta = 1, 
  nthread = 2, nrounds = 5, 
  objective = "binary:logistic", 
  verbose = 2
  )
```

```{r}
# convert to data to matrix
ensayo_SJ_matrix <- as.matrix(ensayo_SJ[ ,..num_feat])
# head(ensayo_SJ_matrix)
prediction_xgboost <- predict(bstSparse, ensayo_SJ_matrix)
# head(prediction_xgboost)
umbral_p = 0.5
prediction_xgboost_binario <- ifelse(prediction_xgboost > umbral_p, 1, 0)
tail(prediction_xgboost_binario)
```

```{r}
# confusion matrix
confusion_matrix <- table(ensayo_SJ$Percibido, prediction_xgboost_binario)

# accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

# sensitivity
sensitivity <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])

# specificity
specificity <- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])

# precision
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])

# F1
F1 <- 2 * (precision * sensitivity) / (precision + sensitivity)

# print the metrics
c(accuracy, sensitivity, specificity, precision, F1)
```
  max.depth = 3, eta = 1, 
  nthread = 2, nrounds = 5, 
[1] 0.9244400 0.8943089 0.9250725 0.2003643 0.3273810








# Corbeille

### logístico otro modelo

```{r}
logit_model_sin <- glm2::glm2(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~ Magnitud + `Proxy_amplitud` + Longitud + Latitud + Profundidad,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
summary(logit_model_sin)
```

```{r}
if(!require("rms")) {
  install.packages("rms")
}
library("rms")

logit1.res <- lrm(
  Percibido ~ Magnitud + `Proxy_amplitud` + `Proxy_energía` + Longitud + Latitud + Profundidad,
  data = entrenamiento_SJ_balanceado,
  y = TRUE, x = TRUE)
residuals(logit1.res, type = "gof")
```
Modelo horrible


#### advanced training xgb.train without

Horrible
```{r}
# convert to data to matrix
num_feat = c("Latitud", "Longitud", "Magnitud", "Profundidad")

label_numeric <- as.numeric(entrenamiento_SJ_balanceado[, Percibido]) - 1
entrenamiento_SJ_matrix <- as.matrix(entrenamiento_SJ[ ,..num_feat])


dtrain <- xgb.DMatrix(
  data = entrenamiento_SJ_matrix, 
  label = label_numeric
)

bstSparse <- xgb.train(
  data = dtrain, 
  max.depth = 20, eta = 1, 
  nthread = 2, nrounds = 1000, 
  objective = "binary:logistic",
  watchlist = list(train = dtrain), 
  verbose = 2
  )
```

```{r}
# convert to data to matrix
ensayo_SJ_matrix <- as.matrix(ensayo_SJ[ ,..num_feat])
# head(ensayo_SJ_matrix)
prediction_xgboost <- predict(bstSparse, ensayo_SJ_matrix)
# head(prediction_xgboost)
umbral_p = 0.5
prediction_xgboost_binario <- ifelse(prediction_xgboost > umbral_p, 1, 0)
tail(prediction_xgboost_binario)
```

```{r}
# confusion matrix
confusion_matrix <- table(ensayo_SJ$Percibido, prediction_xgboost_binario)

# accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

# sensitivity
sensitivity <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])

# specificity
specificity <- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])

# precision
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])

# F1
F1 <- 2 * (precision * sensitivity) / (precision + sensitivity)

# print the metrics
c(accuracy, sensitivity, specificity, precision, F1)
```
No se porque da tan diferente. No me importa, lo ignoro.








#### Múltiples modelos lógisticos
```{r modelr | declaración modelos}
if(!require("modelr")) install.packages("modelr")
library("modelr")

# Creación de fórmulas
logit_formulas <- modelr::formulas(
  .response = ~ Percibido,
  LaLoMPAE = ~ Latitud + Longitud + Magnitud + Profundidad + `Proxy_amplitud` + `Proxy_energía`, 
  LaLoMPA = ~ Latitud + Longitud + Magnitud + Profundidad + `Proxy_amplitud`, 
  LaLoMP = ~ Latitud + Longitud + Magnitud + Profundidad, 
  LoMPAE = ~ Longitud + Magnitud + Profundidad + `Proxy_amplitud` + `Proxy_energía`, 
  LoMPA = ~ Longitud + Magnitud + Profundidad + `Proxy_amplitud`, 
  LoMP = ~ Longitud + Magnitud + Profundidad, 
  MPAE = ~ Magnitud + Profundidad + `Proxy_amplitud` + `Proxy_energía`, 
  MPA = ~ Magnitud + Profundidad + `Proxy_amplitud`, 
  MP = ~ Magnitud + Profundidad, 
  MA = ~ Magnitud + `Proxy_amplitud`,
  PA = ~ Profundidad + `Proxy_amplitud`,
  P = ~ Profundidad,
  A = ~ `Proxy_amplitud`,
  E = ~ `Proxy_energía`,
  M = ~ Magnitud,
)
logit_formulas # observamos el objeto formulas
```

```{r purrr | modelos como logit de glment}
if(!require("purrr")) install.packages("purrr")
library("purrr")

models <- data_frame(logit_formulas) %>% # dataframe a partir del objeto formulas
  mutate(
    models = names(logit_formulas), # columna con los nombres de las formulas
    expression = paste(logit_formulas), # columna con las expresiones de las formulas
    mod = map(
      logit_formulas,
      ~glm(
        ., 
        family = 'binomial',  
        data = entrenamiento_SJ_balanceado,
        )
      )
    ) # Que estamos haciendo acá? Que vamos a encontrar en la columna?
models
```


### glmnet
All the same but using the glmnet library
  
```{r glmnet}
if(!require("glmnet")) {
  install.packages("glmnet")
}
library("glmnet")
```

```{r glmnet summary}
# Fit a logistic regression model
logit_model <- glmnet::glmnet(
  Percibido ~ Magnitud + `Proxy_amplitud` + `Proxy_energía` + Longitud + Latitud + Profundidad,
  data = entrenamiento_SJ_balanceado,
  family = "binomial"
)
```
Didn´t worked, it expecs a matrix of predictors, not a data.table.

```{r glmnet matrix}
# Convert the data to a matrix
X <- model.matrix(Percibido ~ Magnitud + `Proxy_amplitud` + `Proxy_energía` + Longitud + Latitud + Profundidad, data = entrenamiento_SJ_balanceado)
y <- as.numeric(entrenamiento_SJ_balanceado$Percibido) - 1

# Fit a logistic regression model
logit_model_glmnet <- glmnet::glmnet(
  x = X,
  y = y,
  family = "binomial"
)
```

```{r glmnet summary}
summary(logit_model_glmnet)

# coefficients
coef(logit_model_glmnet)

tidy(logit_model_glmnet)
```
No sigo por acá:

The glmnet package does not provide p-values directly because it uses penalized regression techniques that do not rely on traditional statistical inference. However, there is a way to approximate p-values using bootstrapping or cross-validation methods. Here, I'll provide an approach to approximate p-values for glmnet coefficients using cross-validation and refitting the model with glm on the selected variables.

