---
title: "Taller de tesis - Sismos"
author: "Víctor A. Bettachini"
date: "junio de 2024"
output:
  html_document
---

# R restart
```{r restart R}
# System("R")
```

# Capítulo 1: Introducción

## Contexto y motivación científica
Ver manuscrito.

## Objetivo del trabajo / pregunta
Ver manuscrito.


Encontrar los parámetros que más pesan en la percepción de un sismo en Argentina.

Para eso pienso primero probar un modelo de regresión lineal con la variable `Percibido` como dependiente y las demás como independientes.

Algo que me encantaría es factorizar la distancia entre el observador y la coordenada del sismo.
Solo tengo la columna `Provincia`, ¿será la del observador o la del sismo?



## Estructura del documento
Ver manuscrito.



# Capítulo 2: Marco teórico


# Capítulo 3: Metodología

## Presentación y descripción de los datos utilizados
Ver manuscrito.

Elaborados a partir de lo publicado por el [Instituto Nacional de Prevención Sísmica (INPRES)](http://www.inpres.gob.ar/)  
Sistematizados por Daniela Parada del Instituto de cálculo, FCEyN, UBA. [Presentamos un ejemplo para visualización de datos de sismos de Argentina de los últimos 10 años.](https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html) 




## Adquisición y formateo de los datos}


### Carga de los datos

Determino directorios de trabajo según entorno de ejecución.
```{r Directorio de trabajo: ¿Local o GitHub Codespaces?}
if (
  dir.exists(
    file.path(
      "/workspaces"
    )
  )
) {
  setwd("/workspaces/EEA-2023/trabajos_practicos/tp1")
} else {
  setwd(
    "/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/tallerTesis/sismos"
  )
}
```

```{r carga datosIC}
# No funcionó el obtener los datos tras cargar la biblioteca datosIC

# require(devtools)
# devtools::install_github("daniellaparada/datosIC")
# library(datosIC)
# datos <- sismos
# data(sismos)
```



Tras descargar al directorio local el archivo `sismos-arg.csv` desde el url `https://github.com/daniellaparada/IC-datasets-docencia/blob/main/fuente/04_visualizacion/sismos-arg.csv` lo cargo en la data.table `sismos_arg`.

```{r carga data.table , warning=F, message=F}
if (!require("data.table")) {
  install.packages("data.table")
}
library("data.table")

## DT[i, j, by]
##   R:                 i                 j        by
## SQL:  where | order by   select | update  group by
```

Genero la data.table a partir del archivo ubicado en el sendero (path) del sistema de archivos local.
```{r Lectura del archivo}
sismos_all <- fread("./sismos_all.csv", sep = ",") # este no tiene la columna de si fue percibido
sismos_arg <- fread("./sismos-arg.csv", sep = ",")
```

Se verifica que se cargó
```{r head de la data.table}
head(sismos_all)
```

```{r nombres columnas iguales a publicado}
colnames(sismos_arg)
```
Aquí si figura el booleano de si fue percibido



### Verificación de faltantes o duplicados

```{r datos faltantes}
sum(is.na(sismos_arg))
```
No hay registros con "no números" ("not a number" o NA).

```{r datos con cero}
# check at each column for any instance of 0
sapply(sismos_arg, function(x) sum(x == 0))
```
No hay registros idénticos a '0' en ninguna columna.

```{r datos duplicados número}
nrow(sismos_arg)
duplicados <- sismos_arg[duplicated(sismos_arg, fromLast = TRUE)]
#length duplicados
c(nrow(duplicados), nrow(sismos_arg), nrow(duplicados)/nrow(sismos_arg) )
```
Esos 23 registros son un 0.04% de los 55817 registros.

```{r datos duplicados todas las ocurrencias}
# find out whether two rows are equal
all_duplicates <- sismos_arg[duplicated(sismos_arg) | duplicated(sismos_arg, fromLast = TRUE)]
all_duplicates
```

```{r sin duplicados}
sismos <- sismos_arg[!duplicated(sismos_arg)]
```
En `sismos` queda un data.table sin duplicados.



### Inspección y formateo de datos
```{r tipo de dato}
str(sismos)
```


#### Escala continua para fecha y hora del sismo
```{r Segundos del día}
# Function to convert hh:mm:ss to seconds past midnight
convert_to_seconds <- function(time_str) {
  time_posix <- strptime(time_str, format="%H:%M:%S")
  seconds <- as.numeric(format(time_posix, "%H")) * 3600 +
             as.numeric(format(time_posix, "%M")) * 60 +
             as.numeric(format(time_posix, "%S"))
  return(seconds)
}

# Apply the function to the time_str column
sismos[, `Segundos del día` := sapply(Hora, convert_to_seconds)]

summary(sismos[ ,`Segundos del día`, ])
```

```{r día del año}
# consecutive day at the year

# if (!require("lubridate")) {
#   install.packages("lubridate")
# }
# library("lubridate")

# sismos[, `Día del año` := lubridate::yday(as.Date(Fecha, format = "%Y-%m-%d")), ]

sismos[, `Día del año` := yday(as.Date(Fecha, format = "%Y-%m-%d")), ]
summary(sismos[, "Día del año", ], )
```


```{r año}
sismos[, Año := year(as.Date(Fecha, format = "%Y-%m-%d"))]
summary(sismos[,Año])
```



### Delimitación del espacio geográfico

#### Distribución geográfica de los datos
Hay código en (https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html#exploraci%C3%B3n-inicial) pero se tomaron las imágenes de allí.



### El problema de la distancia

### Elección de la provincia de San Juan
```{r select rows with Provincia == San Juan}
sismos_SJ <- sismos[Provincia == "San Juan", ]
# delete column Provincia
sismos_SJ <- sismos_SJ[, Provincia := NULL]
```

```{r registros SJ}
c(nrow(sismos), nrow(sismos_SJ), nrow(sismos_SJ)/nrow(sismos))
```




# Análisis exploratorio de datos
Una básica estadística descriptiva de los datos
```{r resumen de la data.table}
summary(sismos_SJ)
```
Hay un fuerte desbalance en la variable `percibido` que indica si el sismo fue percibido o no hacia este último caso.
  
```{r fracción de no percibidos}
n_percibidos <- sum(sismos_SJ$Percibido == "TRUE")
c(n_percibidos,  n_percibidos / nrow(sismos_SJ) )
```




## Magnitud: distribución lineal y escala de Richter
```{r dplyr}
if (!require("dplyr")) {
  install.packages("dplyr")
}
library("dplyr")
```

```{r Magnitud San Juan}
sismos_SJaux <- sismos_SJ %>%
  mutate(Año = format(Fecha, format = "%Y"))

df <- sismos_SJaux %>%
  filter(Año > 2011,
         Año < 2023) %>%
  group_by(Año, Magnitud) %>%
  summarize(n = n())


df2 <- df %>%
  group_by(Año) %>%
  arrange(-Magnitud) %>%
  summarize(Magnitud = Magnitud,
            nacum = cumsum(n))
```

```{r plotly}
if (!require("plotly")) {
  install.packages("plotly")
}
library("plotly")
```

```{r plot acumulado anuales por magnitud San Juan}
#ggplotly(
#  ggplot(data = df2, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año, key = nacum
#  )) +
#    labs(x = "Magnitud", y = "(Log 10) Cantidad acumulada de sismos") +
#    geom_point() +
#    theme_classic(),
#  source = "select",
#  tooltip = c("key")
#)
```

```{r TikZ}
library(tikzDevice)
if (!require("tikzDevice")) {
  install.packages("tikzDevice")
}
library("tikzDevice")
```

```{r output acumulado anuales por magnitud San Juan tikz}
#tikz('graphs/acumulado_anual_magnitud.tex',width=5,height=3)
#  ggplot(data = df2, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año)) +
#    labs(x = "Magnitud ($M_w$)", y = "Número sismos (Log$_{10}$)") +
#    geom_point() +
#    theme_classic()
#dev.off()
```


```{r Magnitud San Juan percibidos}
df_detectados <- sismos_SJaux %>%
  filter(Año > 2011,
         Año < 2023,
         Percibido == TRUE) %>%
  group_by(Año, Magnitud) %>%
  summarize(n = n())

df2_detectados <- df_detectados %>%
  group_by(Año) %>%
  arrange(-Magnitud) %>%
  summarize(Magnitud = Magnitud,
            nacum = cumsum(n))

#ggplotly(
#  ggplot(data = df2_detectados, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año, key = nacum
#  )) +
#    labs(x = "Magnitud", y = "(Log 10) Cantidad acumulada de sismos") +
#    geom_point() +
#    theme_classic(),
#  source = "select",
#  tooltip = c("key")
#)
```

```{r output acumulado anuales por magnitud San Juan percibidos tikz}
#tikz('graphs/acumulado_anual_magnitud_percibidos.tex',width=5,height=3)
#  ggplot(data = df2_detectados, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año)) +
#    labs(x = "Magnitud ($M_w$)", y = "Número sismos (Log$_{10}$)") +
#    geom_point() +
#    theme_classic()
#dev.off()
```
 



### Horario de los percibidos
```{r percibidos segmentados por hora}
# Create two separate data.tables for TRUE and FALSE cases
dt_true <- sismos_SJ[Percibido == TRUE]
dt_false <- sismos_SJ[Percibido == FALSE]

# Define the breaks for the 24 hours of the day (0 to 86400 seconds)
breaks <- seq(0, 86400, by = 3600)

# Create histograms for TRUE and FALSE cases
hist_true <- hist(dt_true$`Segundos del día`, breaks = breaks, plot = FALSE)
hist_false <- hist(dt_false$`Segundos del día`, breaks = breaks, plot = FALSE)

# Calculate the ratio of counts in each bin
ratio <- hist_true$counts / hist_false$counts

# Create a data.table to hold the result
percibidos_hora <- data.table(
  Hora = floor(hist_true$mids / 3600), # Convert bin midpoints to hours
  Porcentaje = ratio * 100
)

# Handle possible Inf or NA values in the ratio
percibidos_hora[is.infinite(Porcentaje) | is.na(Porcentaje), Porcentaje := NA]

# Print the result
print(percibidos_hora)
```


```{r histograma percibidos segmentados por hora}
#ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
#  geom_bar(stat = "identity") +
#  # labs(title = "Razón de sismos percibidos a no percibidos por hora",
#  labs(
#       x = "Hora",
#       y = "Percibidos [%]")
## percibido_hora_histograma <- recordPlot() # no funca
#
#tikz('graphs/histograma_percibidos_por_hora.tex',width= 4.8,height=2)
## replayPlot(percibido_hora_histograma) @ no funca
#ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
#  geom_bar(stat = "identity") +
#  labs(x = "Hora", y = "Percibidos [\\%]"
#  )
#dev.off()
```


#### Distribución de los sismos percibidos por trimestre
```{r percibidos por trimestre}
trimestre_días = ceiling(366/4)
#
## Define the breaks for the 24 hours of the day (0 to 86400 seconds)
breaks_trimestre <- seq(0, 400, by = trimestre_días)
#
## Create histograms for TRUE and FALSE cases
hist_true_trimestre <- hist(dt_true$`Día del año`, breaks = breaks_trimestre, plot = FALSE)
hist_false_trimestre <- hist(dt_false$`Día del año`, breaks = breaks_trimestre, plot = FALSE)
#
## Calculate the ratio of counts in each bin
ratio_trimestre <- hist_true_trimestre$counts / hist_false_trimestre$counts
#
## Create a data.table to hold the result
percibidos_trimestre <- data.table(
  Trimestre = ceiling(hist_true_trimestre$mids / trimestre_días), # Convert bin midpoints to hours
  Porcentaje_trimestre = ratio_trimestre * 100
)
#
## Handle possible Inf or NA values in the ratio
percibidos_trimestre[is.infinite(Porcentaje_trimestre) | is.na(Porcentaje_trimestre), Porcentaje_trimestre := NA]
#
## Print the result
print(percibidos_trimestre)
```


```{r histograma percibidos segmentados por trimestre}
#ggplot(percibidos_trimestre, aes(x = Trimestre, y = Porcentaje_trimestre)) +
#  geom_bar(stat = "identity") +
##  # labs(title = "Razón de sismos percibidos por trimestre",
#  labs(
#       x = "Trimestre",
#       y = "Percibidos [%]")
### percibidos_trimestre_histograma <- recordPlot() # No funca
#
#tikz('graphs/percibidos_trimestre_histograma.tex',width= 4.8,height=2)
### replayPlot(percibidos_trimestre_histograma) # No funca
#ggplot(percibidos_trimestre, aes(x = Trimestre, y = Porcentaje_trimestre)) +
#  geom_bar(stat = "identity") +
#  labs(x = "", y = "Percibidos [\\%]"
#  )
#dev.off()
```

```{r trimestre}
# data type percibidos_trimestre
str(percibidos_trimestre)

# z-scores
data <- percibidos_trimestre[, Porcentaje_trimestre]
z_scores <- (data - mean(data))/sd(data)
z_scores

# p-values
p_values <- 2 * (1 - pnorm(abs(z_scores)))
p_values
```

```{r trimestre test de Dixon}
if (!require("outliers")) {
  install.packages("outliers")
}
library("outliers")

# Dixon's Q test
outliers::dixon.test(data, opposite = FALSE)
```


```{r data.table with hist_false hist_true}
hist_true_trimestre$counts
hist_false_trimestre$counts
trials = hist_true_trimestre$counts +hist_false_trimestre$counts
prop.test(hist_true_trimestre$counts, trials)
```


```{r trimestre test exacta binomial}
# Group data (successes and trials)
groups <- list('1' = c(215, 8261), '2' = c(152, 7553), '3' = c(112, 6857), '4' = c(138, 7246))
mean_proportion <- mean(sapply(groups, function(group) group[1] / group[2]))

# Perform binomial tests for each group
results <- lapply(names(groups), function(group) {
  successes <- groups[[group]][1]
  trials <- groups[[group]][2]
  test <- binom.test(successes, trials, p = mean_proportion)
  return(list(group = group, p_value = test$p.value, proportion = successes / trials))
})

# Print results
for (result in results) {
  cat(sprintf("Group %s: Proportion = %f, p-value = %f\n", result$group, result$proportion, result$p_value))
}
```

### Ingeniería de características


### Descarte de terromotos de poca profundidad
```{r máxima profundidad}
c(min(sismos_SJ$Profundidad),  max(sismos_SJ$Profundidad) )
```

```{r histograma hasta 50 km profundidad con barras más finas}
#hist(sismos_SJ[Profundidad < 50]$Profundidad, main = "", xlab = "Profundidad [km]", ylab = "Frecuencia", breaks = 50)
#profundidad_menos50 <- recordPlot()
#
##png("graphs/histograma_profundidad_menos50.png", width = 400, height = 400, res = 100)
##replayPlot(profundidad_menos50)
##dev.off()
#
## save as TikZ 
#tikz('graphs/histograma_profundidad_menos50.tex',width=5,height=4) # petite
#replayPlot(profundidad_menos50)
#dev.off()
```

```{r solo registros con profundidad no nula}
# copy of data.table
# sismos_todasProfundidades <- copy(sismos)
sismos_SJ <- sismos_SJ[Profundidad > 0]
```

```{r histograma de Profundidad}
#hist(sismos_SJ$Profundidad, main = "", xlab = "Profundidad [km]", ylab = "Frecuencia", breaks = 50)
#histograma_profundidad750km <- recordPlot()
#
### save as TikZ 
#tikz('graphs/histograma_profundidad750km.tex',width=5,height=4) # petite
#replayPlot(histograma_profundidad750km)
#dev.off()
```



#### Linealización de la Magnitud
Puesto que la escala de Richter es una escala logarítmica me interesaría pasarla a una escala lineal.

> The Richter magnitude of an earthquake is determined from the logarithm of the amplitude of waves recorded by seismographs. Adjustments are included to compensate for the variation in the distance between the various seismographs and the epicenter of the earthquake. The original formula is:
> $$
> M_\mathrm{L} = \log_{10} A - \log_{10} A_\mathrm{0}(\delta) = \log_{10} [A / A_\mathrm{0}(\delta)]
> $$
> 
> Fuente: https://en.wikipedia.org/wiki/Richter_scale

La presunción es que el umbral de percepción estará ligado a la amplitud de oscilación de las ondas sísmicas.  
Aunque también podría pensarse que sería con su potencia, es decir algo proporcional a $A^2$.  
Algo para probar luego, por lo pronto a pasarle a una escala lineal.

```{r proporción más profundos que 50 km}
# only those with Profundidad > 50
c( nrow(sismos_SJ[Profundidad > 50]), nrow(sismos_SJ[Profundidad < 50]) )
nrow(sismos_SJ[Profundidad > 50])/  nrow(sismos_SJ)
```


Sin ponerme a investigar más genero una columna de magnitud_lineal con $10^{M_L}$
```{r min Magnitud}
magnitud_mínima = min(sismos_SJ[,Magnitud, ])
magnitud_mínima
```

```{r Linealizar la escala de Richter}
sismos_SJ[, "Proxy amplitud" := 10^(Magnitud- magnitud_mínima)]
```

```{r descripción para magnitud lineal}
# summary(sismos_SJ$"Proxy amplitud")
summary(sismos_SJ[,'Proxy amplitud'])
```


### Percecpión sísmica, ¿de amplitud o energía?
```{r proxy energía}
sismos_SJ[, `Proxy energía` := `Proxy amplitud`^2]
```



## Variables a correlacionar con la percepción 
```{r variables posibles}
colnames(sismos_SJ)
```


Podría verse si hay puede hacerse un heat map de correlaciones entre estas variables con 'Percibido'.

```{r correlación variables}
# use any tool
corr_alles <- cor(
  sismos_SJ[
    ,
    .(`Latitud`, `Longitud`, `Magnitud`, `Profundidad`, `Proxy amplitud`, `Proxy energía`, Percibido)
    ]
    , use = "complete.obs"
    )
# corr_alles <- cor(sismos_SJ[, .(Hora_decimal, Profundidad, Proxy_amplitud, Percibido)], use = "complete.obs")
# percibido_correlación = str(corr_alles)

# only the last column
percibido_correlación = corr_alles[, 7]

# remove Percibido from percibido_correlación
percibido_correlación <- percibido_correlación[-7]

# sort
percibido_correlación <- percibido_correlación[order(percibido_correlación, decreasing = TRUE)]
percibido_correlación
```

```{r correlación magnitud y longitud}
cor(sismos_SJ[, .(`Longitud`,`Magnitud`)], use = "complete.obs")
```



```{r correlación magnitud y derivados}
cor(sismos_SJ[, .(`Magnitud`, `Proxy amplitud`, `Proxy energía`)], use = "complete.obs")
```




## Preprocesamiento
Las evaluaciones sobre la calidad de los modelos de clasificación generados se realizarán sobre un subconjuntos de ensayo (test) del \(20 \%\) de los datos de la provincia de San Juan, el resto se utilizará para el entrenamiento (train).


### Escalamiento
Previo a la partición (splitting) se realiza un escaleo uniforme sobre todo el conjunto de datos (scaling) de las tres características numéricas.
Para esto se hace uso de la función `scale` de la biblioteca `caret`.
El objeto de hacer esto previo a un ajuste lineal es que los coeficientes de la regresión sean comparables entre sí.

```{r biblioteca caret}
# no utilizo la biblioteca caret
# if (!require("caret")) {
#   install.packages("caret")
# }
# library("caret")
```

```{r escalamiento}
# identify numerical features in the data
numerical_features <- c("Latitud", "Longitud", "Magnitud", "Profundidad", "Proxy amplitud", "Proxy energía")

# copy only numerical features and Percibido
sismos_SJ_escalado <- sismos_SJ[, ..numerical_features, Percibido]
# # copy only numerical features
# sismos_SJ_escalado <- sismos_SJ[, ..numerical_features]

# Scale numerical features
sismos_SJ_escalado[, (numerical_features) := lapply(.SD, scale), .SDcols = numerical_features]

head(sismos_SJ_escalado)
```

```{r test}
# correlation between columns Magnitud and Proxy_amplitud
cor(sismos_SJ$`Proxy amplitud`, sismos_SJ_escalado$Magnitud)
```




### División con estratificación
Dado el desbalance de la clase Percibido comentado en la sección xxx, la división de los datos en subconjuntos entrenamiento y prueba se hará con estratificación usando la función \verb'CreateDataPartion'.

```{r división con estratificación}
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(sismos_SJ_escalado$Percibido, p = 0.8, list = FALSE)
entrenamiento_SJ <- sismos_SJ_escalado[train_index]
ensayo_SJ <- sismos_SJ_escalado[-train_index]

# Print the number of observations in each set
c(nrow(entrenamiento_SJ), nrow(ensayo_SJ))
```


### Corrección del desbalance
```{r corrección del desbalance}
if (!require("ROSE")) {
  install.packages("ROSE")
}
library("ROSE")

# Percibido como factor para el imbalance
entrenamiento_SJ[, Percibido := as.factor(Percibido)]

# Apply the ROSE algorithm to correct the imbalance
# entrenamiento_SJ_balanceado <- ovun.sample(Percibido ~ ., data = entrenamiento_SJ, method = "over", N = nrow(entrenamiento_SJ), seed = 123)$data
entrenamiento_SJ_balanceado <- ROSE(Percibido ~ ., data = entrenamiento_SJ, seed = 123)$data

# Print the number of observations in each set
c(nrow(entrenamiento_SJ_balanceado), nrow(ensayo_SJ))
```

```{r verificación del balanceo}
# Check the balance of the target variable in training set
table(entrenamiento_SJ_balanceado$Percibido)

# Check the balance of the target variable in test set, must still be unbalanced
table(ensayo_SJ$Percibido)
```


## Descripción de las métricas de evaluación de los modelos (si corresponde)


## Descripción de los métodos estadísticos utilizados (si corresponde)
Contar sobre regresión logística aplicada a variables categóricas y sobre el XFGBoost.



### Regresión logística

Utilizaré como base el código de Enfoque estadístico del aprendizaje, clase 9, dedicada a logit.
```{r biblioteca ajuste regresión lineal}
if (!require("glmnet")) {
  install.packages("glmnet")
}
library("glmnet")
```



#### Múltiple sin interacción entre variables

```{r múltiple definición}
# Fit a logistic regression model
logit_model <- glm(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~ Hora_decimal + Profundidad + `Proxy amplitud`  + Latitud + Longitud,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```


```{r múltiple significativos}
# Print the summary of the model
summary(logit_model)
```
Del sumario se indica con p-values que las variables `Profundidad` y `Proxy_amplitud` son significativas, pero no `Hora_decimal`.

```{r múltiple predicciones}
# Make predictions on the test set
prediction_full <- predict(logit_model, newdata = ensayo_SJ, type = "response")

# Print the first few predictions
head(prediction_full)
```

```{r múltiple metrics function}
# Define the prediction metrics function
prediction_metrics <- function(cutoff, predictions, actual) {
  # Example adjustment if Percibido is boolean
  actual <- factor(actual, levels = c(FALSE, TRUE))
  predicted_class <- factor(ifelse(predictions > cutoff, TRUE, FALSE), levels = c(FALSE, TRUE))

  # predicted_class <- ifelse(predictions > cutoff, 1, 0)
  # actual <- factor(actual, levels = c(0, 1))
  # predicted_class <- factor(predicted_class, levels = c(0, 1))
  
  # Ensure there is at least one instance of each class
  if (length(unique(predicted_class)) < 2 || length(unique(actual)) < 2) {
    return(data.frame(
      cutoff = cutoff,
      accuracy = NA,
      sensitivity = NA,
      specificity = NA,
      precision = NA
    ))
  }

  cm <- confusionMatrix(predicted_class, actual, positive = "TRUE")
  
  data.frame(
    cutoff = cutoff,
    accuracy = cm$overall['Accuracy'],
    sensitivity = cm$byClass['Sensitivity'],
    specificity = cm$byClass['Specificity'],
    precision = cm$byClass['Precision']
  )
}
```

```{r múltiple metrics_list}
cutoffs <- seq(0.05, 0.95, by = 0.01)

# Calculate metrics for each cutoff value
metrics_list <- lapply(cutoffs, function(cutoff) {
  prediction_metrics(cutoff, predictions = prediction_full, actual = ensayo_SJ$Percibido)
})

# Print the first few elements of metrics_list to check
head(metrics_list)
```


```{r múltiple metrics plot}
# Combine the list of data frames into a single data frame
logit_pred <- do.call(rbind, metrics_list)

# Reshape the data for plotting
logit_pred <- logit_pred %>%
  pivot_longer(cols = -cutoff, names_to = "term", values_to = "estimate") %>%
  mutate(estimate = round(estimate, 3))

# Plot the results
ggplot(logit_pred, aes(cutoff, estimate, group = term, color = term)) +
  geom_line(size = 1) +
  theme_bw() #+
# labs(
#  title = 'Accuracy, Sensitivity, Specificity y Precision',
#  subtitle = 'Modelo completo',
#  color = ""
#)
```

```{r múltiple metrics plot castellano}
# Assuming logit_pred is your data frame containing metrics like accuracy, sensitivity, etc.

# copy logit_pred to a new data frame
logit_pred_castellano <- copy(logit_pred)

# Translate terms to Spanish
logit_pred_castellano$term <- recode(logit_pred_castellano$term,
                          "accuracy" = "Exactitud",
                          "sensitivity" = "Sensibilidad",
                          "specificity" = "Especificidad",
                          "precision" = "Precisión")

# names(logit_pred_castellano)[names(logit_pred_castellano) == "estimate"] <- "estimación"

# Plot with translated labels
ggplot(logit_pred_castellano, aes(cutoff, estimate, group=term, color=term)) + 
  geom_line(size=1) +
  theme_bw() +
  labs`title = 'Exactitud, Sensibilidad, Especificidad y Precisión',
       subtitle = 'Modelo completo',
       color = "Métricas",
       x = "Umbral de Corte",
       y = "Valor") +
  scale_color_manual(values = c("Exactitud" = "black",
                                "Sensibilidad" = "blue",
                                "Especificidad" = "red",
                                "Precisión" = "green"))
```


```{r save to tikz}
tikz('graphs/múltiple_metrics.tex',width=5,height=3)
ggplot(logit_pred, aes(cutoff, estimate, group = term, color = term)) +
  geom_line(size = 1) +
  theme_bw()
dev.off()
```

let's guess I choose a cutoff of 0.5

```{r múltiple metrics at 0.5}
# Calculate metrics for the chosen cutoff value
prediction_metrics(0.5, predictions = prediction_full, actual = ensayo_SJ$Percibido)
```
