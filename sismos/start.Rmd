---
title: "Taller de tesis - Sismos"
author: "Víctor A. Bettachini"
date: "junio de 2024"
output:
  html_document
---

# R restart
```{r restart R}
# System("R")
```

# Capítulo 1: Introducción

## Contexto y motivación científica
Ver manuscrito.

## Objetivo del trabajo / pregunta
Ver manuscrito.


Encontrar los parámetros que más pesan en la percepción de un sismo en Argentina.

Para eso pienso primero probar un modelo de regresión lineal con la variable `Percibido` como dependiente y las demás como independientes.

Algo que me encantaría es factorizar la distancia entre el observador y la coordenada del sismo.
Solo tengo la columna `Provincia`, ¿será la del observador o la del sismo?



## Estructura del documento
Ver manuscrito.



# Capítulo 2: Marco teórico


# Capítulo 3: Metodología

## Presentación y descripción de los datos utilizados
Ver manuscrito.

Elaborados a partir de lo publicado por el [Instituto Nacional de Prevención Sísmica (INPRES)](http://www.inpres.gob.ar/)  
Sistematizados por Daniela Parada del Instituto de cálculo, FCEyN, UBA. [Presentamos un ejemplo para visualización de datos de sismos de Argentina de los últimos 10 años.](https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html) 




## Preprocesamiento y limpieza de los datos


### Carga de los datos

Determino directorios de trabajo según entorno de ejecución.
```{r Directorio de trabajo: ¿Local o GitHub Codespaces?}
if (
  dir.exists(
    file.path(
      "/workspaces"
    )
  )
) {
  setwd("/workspaces/EEA-2023/trabajos_practicos/tp1")
} else {
  setwd(
    "/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/tallerTesis/sismos"
  )
}
```

```{r carga datosIC}
# No funcionó el obtener los datos tras cargar la biblioteca datosIC

# require(devtools)
# devtools::install_github("daniellaparada/datosIC")
# library(datosIC)
# datos <- sismos
# data(sismos)
```



Tras descargar al directorio local el archivo `sismos-arg.csv` desde el url `https://github.com/daniellaparada/IC-datasets-docencia/blob/main/fuente/04_visualizacion/sismos-arg.csv` lo cargo en la data.table `sismos_arg`.

```{r carga data.table , warning=F, message=F}
if (!require("data.table")) {
  install.packages("data.table")
}
library("data.table")

## DT[i, j, by]
##   R:                 i                 j        by
## SQL:  where | order by   select | update  group by
```

Genero la data.table a partir del archivo ubicado en el sendero (path) del sistema de archivos local.
```{r Lectura del archivo}
sismos_all <- fread("./sismos_all.csv", sep = ",") # este no tiene la columna de si fue percibido
sismos_arg <- fread("./sismos-arg.csv", sep = ",")
```


### Limpieza de datos 


#### Inspección de tipos de datos
Se verifica que se cargó

```{r head de la data.table}
head(sismos_all)
```
En `sismos_all`  los formatos son distintos, pero crucialmente no figura la columna de si fue percibido.

```{r nombres columnas iguales a publicado}
colnames(sismos_arg)
```
Aquí si figura el booleano de si fue percibido

```{r tipo de dato}
str(sismos_arg)
```



#### Valores faltantes o duplicados
```{r datos faltantes}
sum(is.na(sismos_arg))
```
No hay registros con "no números" ("not a number" o NA).

```{r datos con cero}
# check at each column for any instance of 0
sapply(sismos_arg, function(x) sum(x == 0))
```

```{r registros igulas a cero}
# show rows with Profundidad == 0
sismos_arg[Profundidad == 0]
```


```{r datos duplicados número}
nrow(sismos_arg)
duplicados <- sismos_arg[duplicated(sismos_arg, fromLast = TRUE)]
#length duplicados
c(nrow(duplicados), nrow(sismos_arg), nrow(duplicados)/nrow(sismos_arg) )
```
Esos 23 registros son un 0.04% de los 55817 registros.

```{r datos duplicados todas las ocurrencias}
# find out whether two rows are equal
all_duplicates <- sismos_arg[duplicated(sismos_arg) | duplicated(sismos_arg, fromLast = TRUE)]
all_duplicates
```

```{r sin duplicados}
sismos <- sismos_arg[!duplicated(sismos_arg)]
```
En `sismos` queda un data.table sin duplicados.


#### Datos atípicos
Ver sección de Análisis exploratorio de datos.


### Modificaciones de los datos (ingeniería de características)


#### Escala continua para fecha y hora del sismo
```{r Segundos del día}
# Function to convert hh:mm:ss to seconds past midnight
convert_to_seconds <- function(time_str) {
  time_posix <- strptime(time_str, format="%H:%M:%S")
  seconds <- as.numeric(format(time_posix, "%H")) * 3600 +
             as.numeric(format(time_posix, "%M")) * 60 +
             as.numeric(format(time_posix, "%S"))
  return(seconds)
}

# Apply the function to the time_str column
sismos[, `Segundos del día` := sapply(Hora, convert_to_seconds)]

summary(sismos[ ,`Segundos del día`, ])
```

```{r día del año}
if (!require("lubridate")) {
  install.packages("lubridate")
}
library("lubridate")

# consecutive day at the year
sismos[, `Día del año` := lubridate::yday(as.Date(Fecha, format = "%Y-%m-%d")), ]
  
# sismos[, Dia_del_año := as.numeric(as.Date(Fecha, format = "%Y-%m-%d"))]
summary(sismos[, "Día del año", ], )
```


```{r año}
sismos[, Año := year(as.Date(Fecha, format = "%Y-%m-%d"))]
summary(sismos$Año)
```


## Recorte por produndidad

```{r save plot as TikZ}
# install.packages('tikzDevice')
library(tikzDevice)
if (!require("tikzDevice")) {
  install.packages("tikzDevice")
}
library("tikzDevice")
```

```{r histograma de Profundidad con barras más finas}
hist(sismos[Profundidad < 50]$Profundidad, main = "", xlab = "Profundidad [km]", ylab = "Frecuencia", breaks = 50)
profundidad_menos50 <- recordPlot()

#png("graphs/histograma_profundidad_menos50.png", width = 400, height = 400, res = 100)
#replayPlot(profundidad_menos50)
#dev.off()

# save as TikZ 
# tikz('graphs/histograma_profundidad_menos50.tex',width=2.5,height=2.5) # petite
tikz('graphs/histograma_profundidad_menos50.tex',width=5,height=4) # petite
replayPlot(profundidad_menos50)
dev.off()
```

```{r histograma de Profundidad con barras más finas}
```

```{r solo registros con profundidad no nula}
# copy of data.table
sismos_todasProfundidades <- copy(sismos)
sismos <- sismos[Profundidad > 0]
```


#### Linealización de la magnitud
Puesto que la escala de Richter es una escala logarítmica me interesaría pasarla a una escala lineal.

> The Richter magnitude of an earthquake is determined from the logarithm of the amplitude of waves recorded by seismographs. Adjustments are included to compensate for the variation in the distance between the various seismographs and the epicenter of the earthquake. The original formula is:
> $$
> M_\mathrm{L} = \log_{10} A - \log_{10} A_\mathrm{0}(\delta) = \log_{10} [A / A_\mathrm{0}(\delta)]
> $$
> 
> Fuente: https://en.wikipedia.org/wiki/Richter_scale

La presunción es que el umbral de percepción estará ligado a la amplitud de oscilación de las ondas sísmicas.  
Aunque también podría pensarse que sería con su potencia, es decir algo proporcional a $A^2$.  
Algo para probar luego, por lo pronto a pasarle a una escala lineal.

Sin ponerme a investigar más genero una columna de magnitud_lineal con $10^{M_L}$
```{r min Magnitud}
min(sismos[,Magnitud, ])
```

```{r Linealizar la escala de Richter}
sismos[, "Proxy amplitud" := 10^(Magnitud- 2.5)]
```

```{r head de la data.table tras generar Proxy_amplitud}
head(sismos)
```

```{r descripción para magnitud lineal}
summary(sismos$"Proxy amplitud")
```



# Análisis exploratorio de datos
Una básica estadística descriptiva de los datos
```{r resumen de la data.table}
summary(sismos)
```
Hay un fuerte desbalance en la variable `percibido` que indica si el sismo fue percibido o no hacia este último caso.
  
```{r fracción de no percibidos}
sum(sismos$Percibido == "FALSE") / nrow(sismos)
```


## Magnitud: distribución lineal y escala de Richter

```{r histograma de Magnitud con barras más finas}
#hist(sismos$Magnitud, main = "Histograma de Magnitud", xlab = "Magnitud", ylab = "Frecuencia", breaks = 50)

## save the plot
# png("graphs/histograma_magnitud.png")
```

```{r acumulado anuales por magnitud}
if (!require("dplyr")) {
  install.packages("dplyr")
}
library("dplyr")

sismos_SJ <- sismos %>%
# sismos_SJ <- sismos_SJ %>%
  mutate(Año = format(Fecha, format = "%Y"))

df <- sismos_SJ %>%
  filter(Año > 2012,
         Año < 2022) %>%
  group_by(Año, Magnitud) %>%
  summarize(n = n())


df2 <- df %>%
  group_by(Año) %>%
  arrange(-Magnitud) %>%
  summarize(Magnitud = Magnitud,
            nacum = cumsum(n))

if (!require("plotly")) {
  install.packages("plotly")
}
library("plotly")

#ggplotly(
#  ggplot(data = df2, aes(
#    x = Magnitud, y = log(nacum, 10), colour = Año, key = nacum
#  )) +
#    labs(x = "Magnitud [escala Richter]", y = "(Log 10) sismos") +
#    geom_point() +
#    theme_classic(),
#  source = "select",
#  tooltip = c("key")
#)

# # save as pdf
# pdf("graphs/acumulado_anual_magnitud.pdf", width = 12, height = 6, units = "cm")

#tikz('graphs/acumulado_anual_magnitud.tex',width=5,height=2)
## plot(1,main='Hello World!')
#ggplot(data = df2, aes(x = Magnitud, y = log(nacum, 10), colour = Año)) +
#  labs(x = "Magnitud [escala Richter]", y = "(Log 10) sismos") +
#  geom_point() +
#  theme_classic()
#dev.off()
```



### Horario de los percibidos
```{r percibidos segmentados por hora}
# Create two separate data.tables for TRUE and FALSE cases
dt_true <- sismos[Percibido == TRUE]
dt_false <- sismos[Percibido == FALSE]

# Define the breaks for the 24 hours of the day (0 to 86400 seconds)
breaks <- seq(0, 86400, by = 3600)

# Create histograms for TRUE and FALSE cases
hist_true <- hist(dt_true$`Segundos del día`, breaks = breaks, plot = FALSE)
hist_false <- hist(dt_false$`Segundos del día`, breaks = breaks, plot = FALSE)

# Calculate the ratio of counts in each bin
ratio <- hist_true$counts / hist_false$counts

# Create a data.table to hold the result
percibidos_hora <- data.table(
  Hora = floor(hist_true$mids / 3600), # Convert bin midpoints to hours
  Porcentaje = ratio * 100
)

# Handle possible Inf or NA values in the ratio
percibidos_hora[is.infinite(Porcentaje) | is.na(Porcentaje), Porcentaje := NA]

# Print the result
print(percibidos_hora)
```


```{r histograma percibidos segmentados por hora}
# generate a vertical bar plot to reproduce an histogram on data at result
ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
  geom_bar(stat = "identity") +
  # labs(title = "Razón de sismos percibidos a no percibidos por hora",
  labs(
       x = "Hora",
       y = "Percibidos [%]")

## save it to tikz file
#tikz('graphs/histograma_percibidos_por_hora.tex',width= 4.8,height=2)
#ggplot(percibidos_hora, aes(x = Hora, y = Porcentaje)) +
#  geom_bar(stat = "identity") +
#  labs(x = "Hora", y = "Percibidos [\\%]"
#  )
#dev.off()
```


### Distribución geográfica
Hay código en (https://daniellaparada.github.io/IC-datasets-docencia/04_visualizacion.html#exploraci%C3%B3n-inicial) pero se tomaron las imágenes de allí.



## Descripción de la selección de características (si corresponde)

### El problema de la distancia -> San Juan 
```{r select rows with Provincia == San Juan}
sismos_SJ <- sismos[Provincia == "San Juan", ]
```

```{r registros SJ}
c(nrow(sismos), nrow(sismos_SJ), nrow(sismos_SJ)/nrow(sismos))
```


### Latitud y longitud

```{r latitud San Juan}
# find out correlation between latitud and Percibido
cor(sismos_SJ$Latitud, sismos_SJ$Percibido)
```

```{r longitud San Juan}
cor(sismos_SJ$Longitud, sismos_SJ$Percibido)
```


```{r test}
# correlation between columns Magnitud and Proxy_amplitud
cor(sismos_SJ$`Proxy amplitud`, sismos_SJ_escalado$Magnitud)
```




Quedan así un total de tres variables a trabajar en el modelo de clasificación del estado de \verb'Percibido': \verb'Segundos del día', \verb'Profundidad' y  \verb'Proxy amplitud'.

Podría verse si hay puede hacerse un heat map de correlaciones entre estas variables con 'Percibido'.

```{r correlación variables}
# use any tool
corr_alles <- cor(sismos_SJ[, .(Hora_decimal, Profundidad, "Proxy amplitud", Latitud, Longitud, Percibido)], use = "complete.obs")
# corr_alles <- cor(sismos_SJ[, .(Hora_decimal, Profundidad, Proxy_amplitud, Percibido)], use = "complete.obs")
str(corr_alles)
# only the last column
corr_alles[, 6]
```


## Preprocesamiento
Las evaluaciones sobre la calidad de los modelos de clasificación generados se realizarán sobre un subconjuntos de ensayo (test) del \(20 \%\) de los datos de la provincia de San Juan, el resto se utilizará para el entrenamiento (train).


### Escalamiento
Previo a la partición (splitting) se realiza un escaleo uniforme sobre todo el conjunto de datos (scaling) de las tres características numéricas.
Para esto se hace uso de la función `scale` de la biblioteca `caret`.
El objeto de hacer esto previo a un ajuste lineal es que los coeficientes de la regresión sean comparables entre sí.

```{r escalamiento}
# no utilizo la biblioteca caret
if (!require("caret")) {
  install.packages("caret")
}
library("caret")

# copy only some columns
# sismos_SJ_escalado <- sismos_SJ[, .(Hora_decimal, Profundidad, Proxy_amplitud, Percibido)]
# sismos_SJ_escalado <- sismos_SJ[, .(Hora_decimal, Profundidad, Proxy_amplitud, Percibido)]

# # copia
sismos_SJ_escalado <- copy(sismos_SJ)

# Scale numerical features
numerical_features <- c("Hora_decimal", "Profundidad", "Magnitud", 
"Proxy amplitud", "Latitud", "Longitud")
# numerical_features <- c("Hora_decimal", "Profundidad", "Proxy_amplitud")
sismos_SJ_escalado[, (numerical_features) := lapply(.SD, scale), .SDcols = numerical_features]

head(sismos_SJ_escalado)
```




### División con estratificación
Dado el desbalance de la clase Percibido comentado en la sección xxx, la división de los datos en subconjuntos entrenamiento y prueba se hará con estratificación usando la función \verb'CreateDataPartion'.

```{r división con estratificación}
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(sismos_SJ_escalado$Percibido, p = 0.8, list = FALSE)
entrenamiento_SJ <- sismos_SJ_escalado[train_index]
ensayo_SJ <- sismos_SJ_escalado[-train_index]

# Print the number of observations in each set
c(nrow(entrenamiento_SJ), nrow(ensayo_SJ))
```


### Corrección del desbalance
```{r corrección del desbalance}
if (!require("ROSE")) {
  install.packages("ROSE")
}
library("ROSE")

# Percibido como factor para el imbalance
entrenamiento_SJ[, Percibido := as.factor(Percibido)]

# Apply the ROSE algorithm to correct the imbalance
# entrenamiento_SJ_balanceado <- ovun.sample(Percibido ~ ., data = entrenamiento_SJ, method = "over", N = nrow(entrenamiento_SJ), seed = 123)$data
entrenamiento_SJ_balanceado <- ROSE(Percibido ~ ., data = entrenamiento_SJ, seed = 123)$data

# Print the number of observations in each set
c(nrow(entrenamiento_SJ_balanceado), nrow(ensayo_SJ))
```

```{r verificación del balanceo}
# Check the balance of the target variable in training set
table(entrenamiento_SJ_balanceado$Percibido)

# Check the balance of the target variable in test set, must still be unbalanced
table(ensayo_SJ$Percibido)
```


## Descripción de las métricas de evaluación de los modelos (si corresponde)


## Descripción de los métodos estadísticos utilizados (si corresponde)
Contar sobre regresión logística aplicada a variables categóricas y sobre el XFGBoost.



### Regresión logística

Utilizaré como base el código de Enfoque estadístico del aprendizaje, clase 9, dedicada a logit.
```{r biblioteca ajuste regresión lineal}
if (!require("glmnet")) {
  install.packages("glmnet")
}
library("glmnet")
```



#### Múltiple sin interacción entre variables

```{r múltiple definición}
# Fit a logistic regression model
logit_model <- glm(
  # Percibido ~ Hora_decimal + Profundidad + Proxy_amplitud,
  Percibido ~ Hora_decimal + Profundidad + `Proxy amplitud`  + Latitud + Longitud,
   data = entrenamiento_SJ_balanceado,
  family = "binomial"
  )
```


```{r múltiple significativos}
# Print the summary of the model
summary(logit_model)
```
Del sumario se indica con p-values que las variables `Profundidad` y `Proxy_amplitud` son significativas, pero no `Hora_decimal`.

```{r múltiple predicciones}
# Make predictions on the test set
prediction_full <- predict(logit_model, newdata = ensayo_SJ, type = "response")

# Print the first few predictions
head(prediction_full)
```

```{r múltiple metrics function}
# Define the prediction metrics function
prediction_metrics <- function(cutoff, predictions, actual) {
  # Example adjustment if Percibido is boolean
  actual <- factor(actual, levels = c(FALSE, TRUE))
  predicted_class <- factor(ifelse(predictions > cutoff, TRUE, FALSE), levels = c(FALSE, TRUE))

  # predicted_class <- ifelse(predictions > cutoff, 1, 0)
  # actual <- factor(actual, levels = c(0, 1))
  # predicted_class <- factor(predicted_class, levels = c(0, 1))
  
  # Ensure there is at least one instance of each class
  if (length(unique(predicted_class)) < 2 || length(unique(actual)) < 2) {
    return(data.frame(
      cutoff = cutoff,
      accuracy = NA,
      sensitivity = NA,
      specificity = NA,
      precision = NA
    ))
  }

  cm <- confusionMatrix(predicted_class, actual, positive = "TRUE")
  
  data.frame(
    cutoff = cutoff,
    accuracy = cm$overall['Accuracy'],
    sensitivity = cm$byClass['Sensitivity'],
    specificity = cm$byClass['Specificity'],
    precision = cm$byClass['Precision']
  )
}
```

```{r múltiple metrics_list}
cutoffs <- seq(0.05, 0.95, by = 0.01)

# Calculate metrics for each cutoff value
metrics_list <- lapply(cutoffs, function(cutoff) {
  prediction_metrics(cutoff, predictions = prediction_full, actual = ensayo_SJ$Percibido)
})

# Print the first few elements of metrics_list to check
head(metrics_list)
```


```{r múltiple metrics plot}
# Combine the list of data frames into a single data frame
logit_pred <- do.call(rbind, metrics_list)

# Reshape the data for plotting
logit_pred <- logit_pred %>%
  pivot_longer(cols = -cutoff, names_to = "term", values_to = "estimate") %>%
  mutate(estimate = round(estimate, 3))

# Plot the results
ggplot(logit_pred, aes(cutoff, estimate, group = term, color = term)) +
  geom_line(size = 1) +
  theme_bw() #+
# labs(
#  title = 'Accuracy, Sensitivity, Specificity y Precision',
#  subtitle = 'Modelo completo',
#  color = ""
#)
```

```{r múltiple metrics plot castellano}
# Assuming logit_pred is your data frame containing metrics like accuracy, sensitivity, etc.

# copy logit_pred to a new data frame
logit_pred_castellano <- copy(logit_pred)

# Translate terms to Spanish
logit_pred_castellano$term <- recode(logit_pred_castellano$term,
                          "accuracy" = "Exactitud",
                          "sensitivity" = "Sensibilidad",
                          "specificity" = "Especificidad",
                          "precision" = "Precisión")

# names(logit_pred_castellano)[names(logit_pred_castellano) == "estimate"] <- "estimación"

# Plot with translated labels
ggplot(logit_pred_castellano, aes(cutoff, estimate, group=term, color=term)) + 
  geom_line(size=1) +
  theme_bw() +
  labs`title = 'Exactitud, Sensibilidad, Especificidad y Precisión',
       subtitle = 'Modelo completo',
       color = "Métricas",
       x = "Umbral de Corte",
       y = "Valor") +
  scale_color_manual(values = c("Exactitud" = "black",
                                "Sensibilidad" = "blue",
                                "Especificidad" = "red",
                                "Precisión" = "green"))
```


```{r save to tikz}
tikz('graphs/múltiple_metrics.tex',width=5,height=3)
ggplot(logit_pred, aes(cutoff, estimate, group = term, color = term)) +
  geom_line(size = 1) +
  theme_bw()
dev.off()
```

let's guess I choose a cutoff of 0.5

```{r múltiple metrics at 0.5}
# Calculate metrics for the chosen cutoff value
prediction_metrics(0.5, predictions = prediction_full, actual = ensayo_SJ$Percibido)
```
